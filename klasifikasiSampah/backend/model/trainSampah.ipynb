{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFSANTwAayOR",
        "outputId": "6a295746-b895-41ff-836d-9f57c4b9d12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Mount Google Drive (Jika perlu, aktifkan di Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ke dataset\n",
        "DATASET_PATH = \"/content/drive/MyDrive/COMVIS/Kelompok/dataset\"  # Sesuaikan dengan lokasi dataset Anda\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transformasi dengan Augmentasi\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "tivE1Sfn6QVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcKN5jEXbDfn"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = ImageFolder(root=DATASET_PATH, transform=data_transforms)\n",
        "\n",
        "# Split dataset menjadi Train, Validation, Test\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njSQ4U3CeSQJ"
      },
      "outputs": [],
      "source": [
        "# Load Pretrained ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(dataset.classes))  # Sesuaikan output layer dengan jumlah kelas dataset\n",
        "\n",
        "# Freeze semua layer kecuali FC layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Inisialisasi Loss dan Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnrfhXv1eUmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbe86ac-7300-40e5-d80c-f3123a19d557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4629\n",
            "Validation Accuracy: 62.80%\n",
            "Epoch 2/10, Loss: 1.0398\n",
            "Validation Accuracy: 68.60%\n",
            "Epoch 3/10, Loss: 0.8954\n",
            "Validation Accuracy: 73.61%\n",
            "Epoch 4/10, Loss: 0.8061\n",
            "Validation Accuracy: 68.07%\n",
            "Epoch 5/10, Loss: 0.7757\n",
            "Validation Accuracy: 72.82%\n",
            "Epoch 6/10, Loss: 0.7022\n",
            "Validation Accuracy: 79.16%\n",
            "Epoch 7/10, Loss: 0.6999\n",
            "Validation Accuracy: 73.09%\n",
            "Epoch 8/10, Loss: 0.6998\n",
            "Validation Accuracy: 74.14%\n",
            "Epoch 9/10, Loss: 0.7200\n",
            "Validation Accuracy: 78.36%\n",
            "Epoch 10/10, Loss: 0.7027\n",
            "Validation Accuracy: 78.36%\n"
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluasi di Validation Set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB02be99eZsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5d11a4-bc93-4c07-9969-67b70685abaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Simpan Model\n",
        "torch.save(model.state_dict(), \"klasifikasiSampah.pth\")\n",
        "print(\"Model saved successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}